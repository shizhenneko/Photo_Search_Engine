# 个人照片搜索引擎

## 实验目的

构建一个基于多模态 embedding 和 Vision LLM 的个人照片搜索引擎，验证跨模态检索技术在实际应用场景中的有效性，以及 Vision LLM 在图像理解和自然语言描述生成方面的能力。

## 实验内容描述

本实验分为索引阶段和查询阶段两个部分。

**索引阶段(离线处理)**：

1. 照片扫描：遍历用户指定的文件夹，识别所有图片文件
2. 图像描述生成：对每张照片调用 Vision LLM API，生成自然语言描述
3. 嵌入向量生成：使用嵌入模型为每张照片的描述文本生成嵌入向量
4. 索引构建：将照片路径、描述文本、嵌入向量存储到向量数据库中

**查询阶段(在线交互)**：

1. 用户输入：接收用户的自然语言查询，如"去年夏天在海边的照片"、"我和朋友的合影"、"圣诞节的装饰"
2. 查询嵌入：将用户查询转换为嵌入向量
3. 相似度检索：在向量数据库中执行相似度搜索(如余弦相似度、点积)，检索 Top-K 个最匹配的照片
4. 结果展示：以网格或列表形式展示检索到的照片，每张照片附带其自动生成的描述和相似度分数

## 期望验收结果

- 成功索引至少 100 张个人照片，生成的描述准确反映照片内容
- 支持多样化的自然语言查询，包括：
  - 场景查询(如"山上的照片"、"城市夜景")
  - 人物查询(如"有人物的照片"、"集体合影")
  - 活动查询(如"聚餐"、"运动"、"旅行")
  - 时间查询(结合元数据，如"去年的照片"、"冬天的照片")
  - 情感查询(如"欢乐的场景"、"宁静的风景")
